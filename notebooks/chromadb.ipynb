{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from scripts.data_loader import load_medicare_data\n",
    "\n",
    "# assuming notebook is in \"project/notebooks\" and modules are in \"project/scripts\"\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "\n",
    "# Load environment variables from the secrets.env file.\n",
    "load_dotenv(\"secrets.env\")\n",
    "\n",
    "# Retrieve API keys from environment variables.\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sample file: data/processed/sample_ny_data.csv with size: 50000\n"
     ]
    }
   ],
   "source": [
    "# # Add project root to Python path\n",
    "# PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "# sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Load dataset\n",
    "# data = load_medicare_data()\n",
    "file_path = 'data/processed/sample_ny_data.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    # If file does not exist, create new sample\n",
    "    sample_ny_data = load_medicare_data()\n",
    "    print(f\"Creating new sample file: {file_path} with size: {len(sample_ny_data)}\")\n",
    "else:\n",
    "    # If file exists, read it instead of creating new sample\n",
    "    sample_ny_data = pd.read_csv(file_path)\n",
    "    print(f\"Loading existing sample file: {file_path} with size: {len(sample_ny_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# To reuse our Chroma index in LangChain, we can use the same persist_directory.\n",
    "# Here, we assume you persist the index to a local directory.\n",
    "# (Alternatively, you could wrap the existing collection—but LangChain’s Chroma class offers a higher-level interface.)\n",
    "PERSIST_DIR = \"./chroma_db\"\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Instantiate a Chroma client\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "# Create or load the vector store directly using LangChain's Chroma\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIR,\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"new_york_medicare\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ny_data = sample_ny_data.head(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 500/500 [00:00<00:00, 11885.85it/s]\n",
      "Batch Upserting: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_text(row):\n",
    "    # Construct the provider's name (combining first name and last/organization name)\n",
    "    first_name = row.get(\"Rndrng_Prvdr_First_Name\", \"\")\n",
    "    last_org = row.get(\"Rndrng_Prvdr_Last_Org_Name\", \"\")\n",
    "    provider_name = f\"{first_name} {last_org}\".strip()\n",
    "    \n",
    "    # Extract key service details\n",
    "    hcpcs_desc = row.get(\"HCPCS_Desc\", \"\")\n",
    "    \n",
    "    # Instead of Place_Of_Srvc (which indicates facility type), use city and state for location context.\n",
    "    city = row.get(\"Rndrng_Prvdr_City\", \"\")\n",
    "    state = row.get(\"Rndrng_Prvdr_State_Abrvtn\", \"\")\n",
    "    location = f\"{city}, {state}\".strip(\", \")\n",
    "    \n",
    "    # Create the embedding text that includes key information.\n",
    "    embedding_text = f\"Provider: {provider_name}. Service: {hcpcs_desc}. Location: {location}.\"\n",
    "    return embedding_text\n",
    "\n",
    "# Build Document objects directly from the DataFrame rows.\n",
    "docs = []\n",
    "doc_ids = []\n",
    "\n",
    "for i, row in tqdm(sample_ny_data.iterrows(), total=len(sample_ny_data), desc=\"Processing rows\"):\n",
    "    text = create_embedding_text(row)\n",
    "    unique_id = f\"{row.get('Rndrng_NPI', 'unknown')}_{i}\"\n",
    "    docs.append(Document(page_content=text, metadata=row.to_dict()))\n",
    "    doc_ids.append(unique_id)\n",
    "\n",
    "# Batch upsert the documents into the vectorstore.\n",
    "batch_size = 10000\n",
    "num_batches = (len(docs) // batch_size) + 1\n",
    "\n",
    "for batch_idx in tqdm(range(num_batches), desc=\"Batch Upserting\"):\n",
    "    start = batch_idx * batch_size\n",
    "    end = start + batch_size\n",
    "    batch_docs = docs[start:end]\n",
    "    batch_ids = doc_ids[start:end]\n",
    "    if batch_docs:\n",
    "        vectorstore.add_documents(documents=batch_docs, ids=batch_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "# from langchain.llms import LlamaCpp\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a retriever (adjust top_k as needed)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "MODEL_CHOICE = \"deepseek\"  # Change to \"lightweight\" or \"openai\" as desired\n",
    "\n",
    "# Below we provide example setups for each option.\n",
    "if MODEL_CHOICE == \"deepseek\":\n",
    "    llm = ChatOllama(model=\"deepseek-r1\", temperature=0.0)\n",
    "elif MODEL_CHOICE == \"llama2\":\n",
    "    llm = ChatOllama(model=\"llama2\", temperature=0.0)\n",
    "elif MODEL_CHOICE == \"openai\":\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "        # base_url=\"...\",\n",
    "        # organization=\"...\",\n",
    "        # other params...\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Unsupported MODEL_CHOICE. Choose from 'deepseek', 'llama2', or 'openai'.\")\n",
    "\n",
    "\n",
    "# We use LangChain's RetrievalQA chain, which automatically retrieves relevant document chunks\n",
    "# and stuffs them into a prompt for the LLM.\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" simply concatenates the retrieved documents; for long contexts consider \"map_reduce\"\n",
    "    retriever=retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are some physician services that provider White,Devon of 2015 Grand Concourse offers his patients?\n",
      "Answer: <think>\n",
      "Okay, so I need to figure out what services Provider Devon White offers based on the context provided. Let me start by looking through each piece of information given.\n",
      "\n",
      "First, there's a list of providers with their details. Devon White is listed as the provider for a New patient office or other outpatient visit that took 45-59 minutes in the Bronx, NY. That seems straightforward—so he offers general office visits to new patients.\n",
      "\n",
      "Looking further down, I see other providers like George Surguladze and Paul Hodgeman with their respective services. But Devon's entry is clear: it's an office visit for a new patient. There's no mention of any specific tests or specialized services beyond that.\n",
      "\n",
      "I don't see any additional details about Devon's practice or the types of patients he sees, just that it's a general outpatient service. So based on this information, Devon offers general office visits to new patients in the Bronx.\n",
      "</think>\n",
      "\n",
      "Devon White provides general office visits for new patients at his location in the Bronx, NY. These visits typically last between 45-59 minutes and are part of his standard services as an outpatient provider.\n",
      "Retrieved contexts:\n",
      "Document 1:\n",
      "Provider: Devon White. Service: New patient office or other outpatient visit, 45-59 minutes. Location: Bronx, NY.\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Provider: George Surguladze. Service: Hospital observation care on day of discharge. Location: Huntington, NY.\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Provider: Ian Whiteside. Service: X-ray of knee, 1-2 views. Location: Port Jefferson, NY.\n",
      "--------------------------------------------------\n",
      "Document 4:\n",
      "Provider: Evan Bishop-Rimmer. Service: Emergency department visit for problem of high severity. Location: New York, NY.\n",
      "--------------------------------------------------\n",
      "Document 5:\n",
      "Provider: Paul Hodgeman. Service: Advance care planning, first 30 minutes. Location: Johnson City, NY.\n",
      "--------------------------------------------------\n",
      "Document 6:\n",
      "Provider: Michael Rabinowitz. Service: Annual wellness visit, includes a personalized prevention plan of service (pps), subsequent visit. Location: Bronx, NY.\n",
      "--------------------------------------------------\n",
      "Document 7:\n",
      "Provider: Paul Fragner. Service: New patient office or other outpatient visit, 30-44 minutes. Location: White Plains, NY.\n",
      "--------------------------------------------------\n",
      "Document 8:\n",
      "Provider: Joshua Jones. Service: New patient office or other outpatient visit, 45-59 minutes. Location: Amherst, NY.\n",
      "--------------------------------------------------\n",
      "Document 9:\n",
      "Provider: Paul Petrakos. Service: New patient complete exam of visual system. Location: New York, NY.\n",
      "--------------------------------------------------\n",
      "Document 10:\n",
      "Provider: Meredith Jones. Service: Emergency department visit for life threatening or functioning severity. Location: Brooklyn, NY.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\educa\\AppData\\Local\\Temp\\ipykernel_27296\\3786733972.py:6: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "query = \"What are some physician services that provider White,Devon of 2015 Grand Concourse offers his patients?\"\n",
    "answer = qa_chain.run(query)\n",
    "print(\"Query:\", query)\n",
    "print(\"Answer:\", answer)\n",
    "# Retrieve and print the top relevant documents for the query.\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "print(\"Retrieved contexts:\")\n",
    "for idx, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {idx + 1}:\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Results:\n",
      "{'ids': [['doc2', 'doc1']], 'embeddings': None, 'documents': [['Deep learning is a subset of machine learning that uses neural networks with many layers.', 'Machine learning is a field of artificial intelligence that uses statistical techniques to give computers the ability to learn.']], 'uris': None, 'data': None, 'metadatas': [[{'category': 'ML'}, {'category': 'AI'}]], 'distances': [[0.3444952964782715, 0.961942732334137]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "### This is more-so a standard ChromaDB approach, but it's useful to know how to interact with the ChromaDB client directly.\n",
    "\n",
    "# Instantiate a Chroma client.\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "# Create or retrieve a collection with the specified embedding function.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"example_collection\",\n",
    "    embedding_function=default_ef,\n",
    ")\n",
    "\n",
    "# Define some example documents along with optional IDs and metawdata.\n",
    "documents = [\n",
    "    \"Machine learning is a field of artificial intelligence that uses statistical techniques to give computers the ability to learn.\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with many layers.\",\n",
    "    \"Natural Language Processing involves the interaction between computers and human language.\"\n",
    "]\n",
    "doc_ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "metadatas = [\n",
    "    {\"category\": \"AI\"},\n",
    "    {\"category\": \"ML\"},\n",
    "    {\"category\": \"NLP\"}\n",
    "]\n",
    "\n",
    "# Add the documents to the collection. The embedding function automatically creates embeddings.\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=doc_ids\n",
    ")\n",
    "\n",
    "# Define a query to search for relevant documents.\n",
    "query_text = \"What is deep learning?\"\n",
    "results = collection.query(\n",
    "    query_texts=[query_text],\n",
    "    n_results=2  # Number of top results to return.\n",
    ")\n",
    "\n",
    "# Print out the query results.\n",
    "print(\"Query Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from chromadb.utils.embedding_functions import ONNXMiniLM_L6_V2\n",
    "\n",
    "# ef = ONNXMiniLM_L6_V2(preferred_providers=['CUDAExecutionProvider'])\n",
    "\n",
    "# docs = []\n",
    "# for i in range(1000):\n",
    "#     docs.append(f\"this is a document with id {i}\")\n",
    "\n",
    "# start_time = time.perf_counter()\n",
    "# embeddings = ef(docs)\n",
    "# end_time = time.perf_counter()\n",
    "# print(f\"Elapsed time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AzureExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "print(onnxruntime.get_available_providers())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python vdba",
   "language": "python",
   "name": ".conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
