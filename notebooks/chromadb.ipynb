{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from scripts.data_loader import load_medicare_data\n",
    "\n",
    "# assuming notebook is in \"project/notebooks\" and modules are in \"project/scripts\"\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "\n",
    "# Load environment variables from the secrets.env file.\n",
    "load_dotenv(\"secrets.env\")\n",
    "\n",
    "# Retrieve API keys from environment variables.\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sample file: data/processed/sample_ny_data.csv with size: 50000\n"
     ]
    }
   ],
   "source": [
    "# # Add project root to Python path\n",
    "# PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "# sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Load dataset\n",
    "# data = load_medicare_data()\n",
    "file_path = 'data/processed/sample_ny_data.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    # If file does not exist, create new sample\n",
    "    sample_ny_data = load_medicare_data()\n",
    "    print(f\"Creating new sample file: {file_path} with size: {len(sample_ny_data)}\")\n",
    "else:\n",
    "    # If file exists, read it instead of creating new sample\n",
    "    sample_ny_data = pd.read_csv(file_path)\n",
    "    print(f\"Loading existing sample file: {file_path} with size: {len(sample_ny_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\educa\\AppData\\Local\\Temp\\ipykernel_27296\\3934361400.py:25: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# To reuse our Chroma index in LangChain, we can use the same persist_directory.\n",
    "# Here, we assume you persist the index to a local directory.\n",
    "# (Alternatively, you could wrap the existing collection—but LangChain’s Chroma class offers a higher-level interface.)\n",
    "PERSIST_DIR = \"./chroma_db\"\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Instantiate a Chroma client\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "# Create or load the vector store directly using LangChain's Chroma\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIR,\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"new_york_medicare\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ny_data = sample_ny_data.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 500/500 [00:00<00:00, 17849.32it/s]\n",
      "Batch Upserting: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_text(row):\n",
    "    # Construct the provider's name (combining first name and last/organization name)\n",
    "    first_name = row.get(\"Rndrng_Prvdr_First_Name\", \"\")\n",
    "    last_org = row.get(\"Rndrng_Prvdr_Last_Org_Name\", \"\")\n",
    "    provider_name = f\"{first_name} {last_org}\".strip()\n",
    "    \n",
    "    # Extract key service details\n",
    "    hcpcs_desc = row.get(\"HCPCS_Desc\", \"\")\n",
    "    \n",
    "    # Instead of Place_Of_Srvc (which indicates facility type), use city and state for location context.\n",
    "    city = row.get(\"Rndrng_Prvdr_City\", \"\")\n",
    "    state = row.get(\"Rndrng_Prvdr_State_Abrvtn\", \"\")\n",
    "    location = f\"{city}, {state}\".strip(\", \")\n",
    "    \n",
    "    # Create the embedding text that includes key information.\n",
    "    embedding_text = f\"Provider: {provider_name}. Service: {hcpcs_desc}. Location: {location}.\"\n",
    "    return embedding_text\n",
    "\n",
    "# Build Document objects directly from the DataFrame rows.\n",
    "docs = []\n",
    "doc_ids = []\n",
    "\n",
    "for i, row in tqdm(sample_ny_data.iterrows(), total=len(sample_ny_data), desc=\"Processing rows\"):\n",
    "    text = create_embedding_text(row)\n",
    "    unique_id = f\"{row.get('Rndrng_NPI', 'unknown')}_{i}\"\n",
    "    docs.append(Document(page_content=text, metadata=row.to_dict()))\n",
    "    doc_ids.append(unique_id)\n",
    "\n",
    "# Batch upsert the documents into the vectorstore.\n",
    "batch_size = 10000\n",
    "num_batches = (len(docs) // batch_size) + 1\n",
    "\n",
    "for batch_idx in tqdm(range(num_batches), desc=\"Batch Upserting\"):\n",
    "    start = batch_idx * batch_size\n",
    "    end = start + batch_size\n",
    "    batch_docs = docs[start:end]\n",
    "    batch_ids = doc_ids[start:end]\n",
    "    if batch_docs:\n",
    "        vectorstore.add_documents(documents=batch_docs, ids=batch_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing sample file: data/insurance/medicare/2022/sample_ny_data.csv with size: 50000\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/insurance/medicare/2022/sample_ny_data.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    sample_ny_data = ny_data.sample(n=50000, random_state=42)  # random_state for reproducibility\n",
    "    sample_ny_data.to_csv(file_path, index=False)\n",
    "    print(f\"Created new sample file: {file_path}\")\n",
    "else:\n",
    "    # If file exists, read it instead of creating new sample\n",
    "    sample_ny_data = pd.read_csv(file_path)\n",
    "    print(f\"Loading existing sample file: {file_path} with size: {len(sample_ny_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   8%|▊         | 50000/622553 [00:01<00:22, 25244.61it/s]\n",
      "Batch Upserting: 100%|██████████| 6/6 [13:16<00:00, 132.73s/it]\n",
      "Building documents: 100%|██████████| 50000/50000 [00:00<00:00, 174720.88it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ONNXMiniLM_L6_V2' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 78\u001b[39m\n",
      "\u001b[32m     72\u001b[39m docs = [\n",
      "\u001b[32m     73\u001b[39m     Document(page_content=doc, metadata=meta)\n",
      "\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m doc, meta \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(documents, metadatas), total=\u001b[38;5;28mlen\u001b[39m(documents), desc=\u001b[33m\"\u001b[39m\u001b[33mBuilding documents\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     75\u001b[39m ]\n",
      "\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Rebuild the LangChain Chroma vectorstore with the new documents.\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m vectorstore = \u001b[43mLC_Chroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_ef\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPERSIST_DIR\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnew_york_medicare\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[32m     83\u001b[39m \u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\educa\\Projects\\vdba\\.conda\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n",
      "\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\educa\\Projects\\vdba\\.conda\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n",
      "\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n",
      "\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n",
      "\u001b[32m    838\u001b[39m         api=chroma_collection._client,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "\u001b[32m    839\u001b[39m         ids=ids,\n",
      "\u001b[32m    840\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[32m    841\u001b[39m         documents=texts,\n",
      "\u001b[32m    842\u001b[39m     ):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n",
      "\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\educa\\Projects\\vdba\\.conda\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n",
      "\u001b[32m    275\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n",
      "\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m(texts)\n",
      "\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n",
      "\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n",
      "\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n",
      "\u001b[32m    281\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: 'ONNXMiniLM_L6_V2' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from langchain.vectorstores import Chroma as LC_Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# To reuse our Chroma index in LangChain, we can use the same persist_directory.\n",
    "# Here, we assume you persist the index to a local directory.\n",
    "# (Alternatively, you could wrap the existing collection—but LangChain’s Chroma class offers a higher-level interface.)\n",
    "PERSIST_DIR = \"./chroma_db\"\n",
    "\n",
    "# Instantiate a Chroma client.\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "# Create or retrieve a collection with the specified embedding function.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"new_york_medicare\",\n",
    "    embedding_function=local_embedding,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the LangChain Chroma vectorstore with the new documents.\n",
    "vectorstore = LC_Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=local_embedding,\n",
    "    persist_directory=PERSIST_DIR,\n",
    "    collection_name=\"new_york_medicare\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Results:\n",
      "{'ids': [['doc2', 'doc1']], 'embeddings': None, 'documents': [['Deep learning is a subset of machine learning that uses neural networks with many layers.', 'Machine learning is a field of artificial intelligence that uses statistical techniques to give computers the ability to learn.']], 'uris': None, 'data': None, 'metadatas': [[{'category': 'ML'}, {'category': 'AI'}]], 'distances': [[0.3444952964782715, 0.961942732334137]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "### This is more-so a standard ChromaDB approach, but it's useful to know how to interact with the ChromaDB client directly.\n",
    "\n",
    "# Instantiate a Chroma client.\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "# Create or retrieve a collection with the specified embedding function.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"example_collection\",\n",
    "    embedding_function=default_ef,\n",
    ")\n",
    "\n",
    "# Define some example documents along with optional IDs and metawdata.\n",
    "documents = [\n",
    "    \"Machine learning is a field of artificial intelligence that uses statistical techniques to give computers the ability to learn.\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with many layers.\",\n",
    "    \"Natural Language Processing involves the interaction between computers and human language.\"\n",
    "]\n",
    "doc_ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "metadatas = [\n",
    "    {\"category\": \"AI\"},\n",
    "    {\"category\": \"ML\"},\n",
    "    {\"category\": \"NLP\"}\n",
    "]\n",
    "\n",
    "# Add the documents to the collection. The embedding function automatically creates embeddings.\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=doc_ids\n",
    ")\n",
    "\n",
    "# Define a query to search for relevant documents.\n",
    "query_text = \"What is deep learning?\"\n",
    "results = collection.query(\n",
    "    query_texts=[query_text],\n",
    "    n_results=2  # Number of top results to return.\n",
    ")\n",
    "\n",
    "# Print out the query results.\n",
    "print(\"Query Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What services did Filamer Kabigting provide?\n",
      "Answer: <think>\n",
      "Okay, so I need to figure out what services Filamer Kabigting provided based on the context given. Let me start by reading through all the information carefully.\n",
      "\n",
      "Looking at each provider and their services:\n",
      "\n",
      "1. James Kalchbrenner: Offers therapy using exercise for strength, endurance, range of motion, and flexibility, each 15 minutes in Scarsdale, NY.\n",
      "2. Raymond Kruk: Provides an annual wellness visit with a personalized prevention plan (pps) followed by another visit, located in Wappingers Falls, NY.\n",
      "3. Mark Krasner: Offers therapy using functional activities in Brooklyn, NY.\n",
      "4. Arthur Kornblit: Similar to Raymond, offers an annual wellness visit with pps and subsequent visit in Baldwin, NY.\n",
      "5. Robert Krinsky: Provides office or outpatient visits for evaluating and managing established patients without needing a healthcare professional present, located in Woodmere, NY.\n",
      "6. Gemma Kaunert: Offers chronic care management services for two or more chronic conditions, with 20 minutes of clinical staff time each month, in New York, NY.\n",
      "7. Jacob Schachter: Provides advance care planning, first 30 minutes, in Brooklyn, NY.\n",
      "8. Thomas Fiorentino: Offers annual wellness visits with pps and subsequent visit in Yonkers, NY.\n",
      "9. Lori Karchinski: Provides therapy using manual technique, each 15 minutes, in Whitestone, NY.\n",
      "10. Michael Kulesa: Offers therapy for a range of mental processes, initial 15 minutes, in Babylon, NY.\n",
      "\n",
      "Now, the question is about Filamer Kabigting's services. I don't see any entry for Filamer Kabigting in this list. All providers are listed with their names and services. Since there's no mention of Filamer Kabigting here, I can't find out what services he provided based on the given context.\n",
      "\n",
      "I should make sure I didn't miss anything. Let me go through each provider again to confirm if there's any entry for Filamer Kabigting. Nope, it doesn't appear. So, according to the information provided, Filamer Kabigting isn't listed among the providers who offer these services.\n",
      "</think>\n",
      "\n",
      "Based on the provided context, there is no information available about the services offered by Filamer Kabigting. The list of providers includes James Kalchbrenner, Raymond Kruk, Mark Krasner, Arthur Kornblit, Robert Krinsky, Gemma Kaunert, Jacob Schachter, Thomas Fiorentino, Lori Karchinski, and Michael Kulesa, each with their respective services. Filamer Kabigting is not mentioned among these providers.\n",
      "\n",
      "Answer: The information provided does not include any details about the services offered by Filamer Kabigting.\n",
      "Retrieved contexts:\n",
      "Document 1:\n",
      "Provider: James Kalchbrenner. Service: Therapy procedure using exercise to develop strength, endurance, range of motion, and flexibility, each 15 minutes. Location: Scarsdale, NY.\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Provider: Raymond Kruk. Service: Annual wellness visit, includes a personalized prevention plan of service (pps), subsequent visit. Location: Wappingers Falls, NY.\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Provider: Mark Krasner. Service: Therapy procedure using functional activities. Location: Brooklyn, NY.\n",
      "--------------------------------------------------\n",
      "Document 4:\n",
      "Provider: Arthur Kornblit. Service: Annual wellness visit, includes a personalized prevention plan of service (pps), subsequent visit. Location: Baldwin, NY.\n",
      "--------------------------------------------------\n",
      "Document 5:\n",
      "Provider: Robert Krinsky. Service: Office or other outpatient visit for the evaluation and management of established patient that may not require presence of healthcare professional. Location: Woodmere, NY.\n",
      "--------------------------------------------------\n",
      "Document 6:\n",
      "Provider: Gemma Kaunert. Service: Chronic care management services for two or more chronic conditions, additional 20 minutes of clinical staff time directed by health care professional, per calendar month. Location: New York, NY.\n",
      "--------------------------------------------------\n",
      "Document 7:\n",
      "Provider: Jacob Schachter. Service: Advance care planning, first 30 minutes. Location: Brooklyn, NY.\n",
      "--------------------------------------------------\n",
      "Document 8:\n",
      "Provider: Thomas Fiorentino. Service: Annual wellness visit, includes a personalized prevention plan of service (pps), subsequent visit. Location: Yonkers, NY.\n",
      "--------------------------------------------------\n",
      "Document 9:\n",
      "Provider: Lori Karchinski. Service: Therapy procedure using manual technique, each 15 minutes. Location: Whitestone, NY.\n",
      "--------------------------------------------------\n",
      "Document 10:\n",
      "Provider: Michael Kulesa. Service: Therapy procedure for a range of mental processes, initial 15 minutes. Location: Babylon, NY.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "# from langchain.llms import LlamaCpp\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a retriever (adjust top_k as needed)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "MODEL_CHOICE = \"deepseek\"  # Change to \"lightweight\" or \"openai\" as desired\n",
    "\n",
    "# Below we provide example setups for each option.\n",
    "if MODEL_CHOICE == \"deepseek\":\n",
    "    llm = ChatOllama(model=\"deepseek-r1\", temperature=0.0)\n",
    "elif MODEL_CHOICE == \"llama2\":\n",
    "    llm = ChatOllama(model=\"llama2\", temperature=0.0)\n",
    "elif MODEL_CHOICE == \"openai\":\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "        # base_url=\"...\",\n",
    "        # organization=\"...\",\n",
    "        # other params...\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Unsupported MODEL_CHOICE. Choose from 'deepseek', 'llama2', or 'openai'.\")\n",
    "\n",
    "\n",
    "# We use LangChain's RetrievalQA chain, which automatically retrieves relevant document chunks\n",
    "# and stuffs them into a prompt for the LLM.\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" simply concatenates the retrieved documents; for long contexts consider \"map_reduce\"\n",
    "    retriever=retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are some physician services that provider White,Devon of 2015 Grand Concourse offers his patients?\n",
      "Answer: <think>\n",
      "Okay, so I need to figure out what services Provider White, Devon of 2015 Grand Concourse offers his patients based on the context provided. Let me start by looking through each piece of data given.\n",
      "\n",
      "First, there are several entries from Devon White. Each one mentions a service and sometimes a location in the Bronx or Cooperstown, NY. The services vary: some say \"Established patient office or other outpatient visit\" with different time ranges like 10-19 minutes, 30-39 minutes, etc., and another entry is an emergency department visit for high severity.\n",
      "\n",
      "Looking at the other providers, Robert Christopher offers an emergency service in Grand Island, NY. Brian White also has an established patient office or outpatient visit taking 30-39 minutes in Cooperstown. Michael White does the same but in Geneva. Pascale White mentions a new patient office with a longer time frame of 45-59 minutes in New York. Michael Gioscia offers a new patient service in White Plains, NY, taking between 60-74 minutes. James Bregman and Brett Cherrington also have emergency services but in different locations.\n",
      "\n",
      "Focusing back on Devon White, the entries are all about established or new patient office visits with various time durations. The only mention of an emergency department is once for high severity. So it seems Devon's main offerings are routine office visits with different visit types and timing, plus one emergency case.\n",
      "\n",
      "I should make sure I'm not mixing up the providers. Devon White has multiple entries, all in the Bronx area except one which mentions Cooperstown but that's Brian White. So Devon is consistent in his services across his locations.\n",
      "</think>\n",
      "\n",
      "Devon White offers the following services to his patients:\n",
      "\n",
      "1. **Established Patient Office Visits**: These are routine visits with varying time frames:\n",
      "   - 10-19 minutes\n",
      "   - 30-39 minutes (two instances)\n",
      "   - 45-59 minutes\n",
      "\n",
      "2. **New Patient Office Visits**: Typically taking 30-39 minutes.\n",
      "\n",
      "Additionally, Devon White provides an emergency department visit for a high severity issue in Cooperstown, NY.\n",
      "Retrieved contexts:\n",
      "Document 1:\n",
      "Provider: Devon White. Service: Established patient office or other outpatient visit, 10-19 minutes. Location: Bronx, NY.\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "Provider: Devon White. Service: New patient office or other outpatient visit, 45-59 minutes. Location: Bronx, NY.\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "Provider: Devon White. Service: Established patient office or other outpatient visit, 30-39 minutes. Location: Bronx, NY.\n",
      "--------------------------------------------------\n",
      "Document 4:\n",
      "Provider: Robert Christopher. Service: Emergency department visit for problem of high severity. Location: Grand Island, NY.\n",
      "--------------------------------------------------\n",
      "Document 5:\n",
      "Provider: Brian White. Service: Established patient office or other outpatient visit, 30-39 minutes. Location: Cooperstown, NY.\n",
      "--------------------------------------------------\n",
      "Document 6:\n",
      "Provider: Michael White. Service: Established patient office or other outpatient visit, 30-39 minutes. Location: Geneva, NY.\n",
      "--------------------------------------------------\n",
      "Document 7:\n",
      "Provider: Pascale White. Service: New patient office or other outpatient visit, 45-59 minutes. Location: New York, NY.\n",
      "--------------------------------------------------\n",
      "Document 8:\n",
      "Provider: Michael Gioscia. Service: New patient office or other outpatient visit, 60-74 minutes. Location: White Plains, NY.\n",
      "--------------------------------------------------\n",
      "Document 9:\n",
      "Provider: James Bregman. Service: Emergency department visit for problem of mild to moderate severity. Location: White Plains, NY.\n",
      "--------------------------------------------------\n",
      "Document 10:\n",
      "Provider: Brett Cherrington. Service: Emergency department visit for problem of moderate severity. Location: Syracuse, NY.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"What are some physician services that provider White,Devon of 2015 Grand Concourse offers his patients?\"\n",
    "answer = qa_chain.run(query)\n",
    "print(\"Query:\", query)\n",
    "print(\"Answer:\", answer)\n",
    "# Retrieve and print the top relevant documents for the query.\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "print(\"Retrieved contexts:\")\n",
    "for idx, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {idx + 1}:\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from chromadb.utils.embedding_functions import ONNXMiniLM_L6_V2\n",
    "\n",
    "# ef = ONNXMiniLM_L6_V2(preferred_providers=['CUDAExecutionProvider'])\n",
    "\n",
    "# docs = []\n",
    "# for i in range(1000):\n",
    "#     docs.append(f\"this is a document with id {i}\")\n",
    "\n",
    "# start_time = time.perf_counter()\n",
    "# embeddings = ef(docs)\n",
    "# end_time = time.perf_counter()\n",
    "# print(f\"Elapsed time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AzureExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "print(onnxruntime.get_available_providers())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python vdba",
   "language": "python",
   "name": ".conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
