{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datasets\n",
    "1. Insurance\n",
    "2. Health\n",
    "3. Legal\n",
    "4. Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported Chroma API implementation rest",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     19\u001b[39m embedding_function = OpenAIEmbeddingFunction(\n\u001b[32m     20\u001b[39m     api_key=openai_api_key,  \u001b[38;5;66;03m# Uses the API key from secrets.env\u001b[39;00m\n\u001b[32m     21\u001b[39m     model_name=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-ada-002\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# You can change this to any supported model.\u001b[39;00m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Instantiate a Chroma client.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m client = \u001b[43mchromadb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_api_impl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_server_host\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocalhost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_server_http_port\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m8000\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Create or retrieve a collection with the specified embedding function.\u001b[39;00m\n\u001b[32m     32\u001b[39m collection = client.get_or_create_collection(\n\u001b[32m     33\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mexample_collection\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     34\u001b[39m     embedding_function=embedding_function\n\u001b[32m     35\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\educa\\Projects\\vdba\\.conda\\Lib\\site-packages\\chromadb\\__init__.py:333\u001b[39m, in \u001b[36mClient\u001b[39m\u001b[34m(settings, tenant, database)\u001b[39m\n\u001b[32m    330\u001b[39m tenant = \u001b[38;5;28mstr\u001b[39m(tenant)\n\u001b[32m    331\u001b[39m database = \u001b[38;5;28mstr\u001b[39m(database)\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClientCreator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\educa\\Projects\\vdba\\.conda\\Lib\\site-packages\\chromadb\\api\\client.py:58\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, tenant, database, settings)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     54\u001b[39m     tenant: \u001b[38;5;28mstr\u001b[39m = DEFAULT_TENANT,\n\u001b[32m     55\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m     56\u001b[39m     settings: Settings = Settings(),\n\u001b[32m     57\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.tenant = tenant\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.database = database\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\educa\\Projects\\vdba\\.conda\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:18\u001b[39m, in \u001b[36mSharedSystemClient.__init__\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     16\u001b[39m     settings: Settings = Settings(),\n\u001b[32m     17\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28mself\u001b[39m._identifier = \u001b[43mSharedSystemClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_identifier_from_settings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     SharedSystemClient._create_system_if_not_exists(\u001b[38;5;28mself\u001b[39m._identifier, settings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\educa\\Projects\\vdba\\.conda\\Lib\\site-packages\\chromadb\\api\\shared_system_client.py:65\u001b[39m, in \u001b[36mSharedSystemClient._get_identifier_from_settings\u001b[39m\u001b[34m(settings)\u001b[39m\n\u001b[32m     63\u001b[39m     identifier = \u001b[38;5;28mstr\u001b[39m(uuid.uuid4())\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported Chroma API implementation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_impl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m identifier\n",
      "\u001b[31mValueError\u001b[39m: Unsupported Chroma API implementation rest"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "# If you plan to use a HuggingFace local model, import the relevant embedding function.\n",
    "# from chromadb.utils.embedding_functions import HuggingFaceEmbeddingFunction\n",
    "\n",
    "# Load environment variables from the secrets.env file.\n",
    "load_dotenv(\"secrets.env\")\n",
    "\n",
    "# Retrieve API keys from environment variables.\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "# Choose your embedding function.\n",
    "# In this example, we default to OpenAI. If you want to use a HuggingFace model,\n",
    "# you could add logic here to choose based on a configuration variable.\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=openai_api_key,  # Uses the API key from secrets.env\n",
    "    model_name=\"text-embedding-ada-002\"  # You can change this to any supported model.\n",
    ")\n",
    "\n",
    "# Instantiate a Chroma client.\n",
    "client = chromadb.Client(Settings(\n",
    "    chroma_api_impl=\"rest\",\n",
    "    chroma_server_host=\"localhost\",\n",
    "    chroma_server_http_port=\"8000\"\n",
    "))\n",
    "\n",
    "# Create or retrieve a collection with the specified embedding function.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"example_collection\",\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# Define some example documents along with optional IDs and metadata.\n",
    "documents = [\n",
    "    \"Machine learning is a field of artificial intelligence that uses statistical techniques to give computers the ability to learn.\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with many layers.\",\n",
    "    \"Natural Language Processing involves the interaction between computers and human language.\"\n",
    "]\n",
    "doc_ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "metadatas = [\n",
    "    {\"category\": \"AI\"},\n",
    "    {\"category\": \"ML\"},\n",
    "    {\"category\": \"NLP\"}\n",
    "]\n",
    "\n",
    "# Add the documents to the collection. The embedding function automatically creates embeddings.\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=doc_ids\n",
    ")\n",
    "\n",
    "# Define a query to search for relevant documents.\n",
    "query_text = \"What is deep learning?\"\n",
    "results = collection.query(\n",
    "    query_texts=[query_text],\n",
    "    n_results=2  # Number of top results to return.\n",
    ")\n",
    "\n",
    "# Print out the query results.\n",
    "print(\"Query Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PineconeDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Load environment variables from the secrets.env file.\n",
    "load_dotenv(\"secrets.env\")\n",
    "\n",
    "# Retrieve API keys from environment variables.\n",
    "# openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index = pc.Index(pinecone_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(\n",
    "    vectors=[\n",
    "        {\n",
    "            \"id\": \"vec1\", \n",
    "            \"values\": [1.0, 1.5], \n",
    "            \"metadata\": {\"genre\": \"drama\"}\n",
    "        }, {\n",
    "            \"id\": \"vec2\",\n",
    "            \"values\": [2.0, 1.0], \n",
    "            \"metadata\": {\"genre\": \"action\"}\n",
    "        }, {\n",
    "            \"id\": \"vec3\",\n",
    "            \"values\": [0.1, 0.3], \n",
    "            \"metadata\": {\"genre\": \"drama\"}\n",
    "        }, {\n",
    "            \"id\": \"vec4\", \n",
    "            \"values\": [1.0, -2.5], \n",
    "            \"metadata\": {\"genre\": \"action\"}\n",
    "        }\n",
    "    ],\n",
    "    namespace= \"ns1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\n",
    "    namespace=\"ns1\",\n",
    "    vector=[0.1, 0.3],\n",
    "    top_k=2,\n",
    "    include_values=True,\n",
    "    include_metadata=True,\n",
    "    filter={\"genre\": {\"$eq\": \"action\"}}\n",
    ")\n",
    "    \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "conn = psycopg.connect(dbname='pgvector_example', autocommit=True)\n",
    "\n",
    "conn.execute('CREATE EXTENSION IF NOT EXISTS vector')\n",
    "register_vector(conn)\n",
    "\n",
    "conn.execute('DROP TABLE IF EXISTS documents')\n",
    "conn.execute('CREATE TABLE documents (id bigserial PRIMARY KEY, content text, embedding vector(384))')\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "input = [\n",
    "    'The dog is barking',\n",
    "    'The cat is purring',\n",
    "    'The bear is growling'\n",
    "]\n",
    "embeddings = model.encode(input)\n",
    "for content, embedding in zip(input, embeddings):\n",
    "    conn.execute('INSERT INTO documents (content, embedding) VALUES (%s, %s)', (content, embedding))\n",
    "\n",
    "query = 'forest'\n",
    "query_embedding = model.encode(query)\n",
    "result = conn.execute('SELECT content FROM documents ORDER BY embedding <=> %s LIMIT 5', (query_embedding,)).fetchall()\n",
    "for row in result:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure CosmoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
