{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "from scripts.data_loader import load_medicare_data\n",
    "# If you plan to use a HuggingFace local model, import the relevant embedding function.\n",
    "# from chromadb.utils.embedding_functions import HuggingFaceEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "\n",
    "# Load environment variables from the secrets.env file.\n",
    "load_dotenv(\"secrets.env\")\n",
    "\n",
    "# Retrieve API keys from environment variables.\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "# Load dataset\n",
    "data = load_medicare_data().head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Function\n",
    "\n",
    "# # Choose embedding function.\n",
    "# embedding_function = OpenAIEmbeddingFunction(\n",
    "#     api_key=openai_api_key,  # Uses the API key from secrets.env\n",
    "#     model_name=\"text-embedding-ada-002\"  # You can change this to any supported model.\n",
    "# )\n",
    "\n",
    "# local\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer(\"all-MiniLM-L12-v2\")\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\educa\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02<00:00, 40.9MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Results:\n",
      "{'ids': [['doc2', 'doc1']], 'embeddings': None, 'documents': [['Deep learning is a subset of machine learning that uses neural networks with many layers.', 'Machine learning is a field of artificial intelligence that uses statistical techniques to give computers the ability to learn.']], 'uris': None, 'data': None, 'metadatas': [[{'category': 'ML'}, {'category': 'AI'}]], 'distances': [[0.3444952964782715, 0.961942732334137]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Chroma client.\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "# Create or retrieve a collection with the specified embedding function.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"example_collection\",\n",
    "    embedding_function=default_ef\n",
    ")\n",
    "\n",
    "# Define some example documents along with optional IDs and metadata.\n",
    "documents = [\n",
    "    \"Machine learning is a field of artificial intelligence that uses statistical techniques to give computers the ability to learn.\",\n",
    "    \"Deep learning is a subset of machine learning that uses neural networks with many layers.\",\n",
    "    \"Natural Language Processing involves the interaction between computers and human language.\"\n",
    "]\n",
    "doc_ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "metadatas = [\n",
    "    {\"category\": \"AI\"},\n",
    "    {\"category\": \"ML\"},\n",
    "    {\"category\": \"NLP\"}\n",
    "]\n",
    "\n",
    "# Add the documents to the collection. The embedding function automatically creates embeddings.\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=doc_ids\n",
    ")\n",
    "\n",
    "# Define a query to search for relevant documents.\n",
    "query_text = \"What is deep learning?\"\n",
    "results = collection.query(\n",
    "    query_texts=[query_text],\n",
    "    n_results=2  # Number of top results to return.\n",
    ")\n",
    "\n",
    "# Print out the query results.\n",
    "print(\"Query Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
